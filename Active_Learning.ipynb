{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy/4dEfDNroHVHQvsYbDE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emredeveloper/Machine-Learning-Codes/blob/main/Active_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZiobhPXME03m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into test set, train set and unlabel pool\n",
        "def split(dataset, train_size, test_size):\n",
        "\tx = dataset[:, :-1]\n",
        "\ty = dataset[:, -1]\n",
        "\tx_train, x_pool, y_train, y_pool = train_test_split(\n",
        "\t\tx, y, train_size = train_size)\n",
        "\tunlabel, x_test, label, y_test = train_test_split(\n",
        "\t\tx_pool, y_pool, test_size = test_size)\n",
        "\treturn x_train, y_train, x_test, y_test, unlabel, label\n"
      ],
      "metadata": {
        "id": "6-dIV8eiE69P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\t# read dataset\n",
        "\tdataset = pd.read_csv(\n",
        "\t\t\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\").values[:, ]\n",
        "\n",
        "\t# imputing missing data\n",
        "\timputer = SimpleImputer(missing_values=0, strategy=\"mean\")\n",
        "\timputer = imputer.fit(dataset[:, :-1])\n",
        "\tdataset[:, :-1] = imputer.transform(dataset[:, :-1])\n",
        "\n",
        "\t# feature scaling\n",
        "\tsc = StandardScaler()\n",
        "\tdataset[:, :-1] = sc.fit_transform(dataset[:, :-1])\n",
        "\n",
        "\t# run both models 100 times and take the average of their accuracy\n",
        "\tac1, ac2 = [], [] # arrays to store accuracy of different models\n",
        "\n",
        "\tfor i in range(200):\n",
        "\t\t# split dataset into train(5 %), test(25 %), unlabel(70 %)\n",
        "\t\tx_train, y_train, x_test, y_test, unlabel, label = split(\n",
        "\t\t\tdataset, 0.05, 0.25)\n",
        "\n",
        "\t\t# train model by active learning\n",
        "\t\tfor i in range(10):\n",
        "\t\t\tclassifier1 = LogisticRegression()\n",
        "\t\t\tclassifier1.fit(x_train, y_train)\n",
        "\t\t\ty_probab = classifier1.predict_proba(unlabel)[:, 0]\n",
        "\t\t\tp = 0.47 # range of uncertanity 0.47 to 0.53\n",
        "\t\t\tuncrt_pt_ind = []\n",
        "\t\t\tfor i in range(unlabel.shape[0]):\n",
        "\t\t\t\tif(y_probab[i] >= p and y_probab[i] <= 1-p):\n",
        "\t\t\t\t\tuncrt_pt_ind.append(i)\n",
        "\t\t\tx_train = np.append(unlabel[uncrt_pt_ind, :], x_train, axis=0)\n",
        "\t\t\ty_train = np.append(label[uncrt_pt_ind], y_train)\n",
        "\t\t\tunlabel = np.delete(unlabel, uncrt_pt_ind, axis=0)\n",
        "\t\t\tlabel = np.delete(label, uncrt_pt_ind)\n",
        "\t\tclassifier2 = LogisticRegression()\n",
        "\t\tclassifier2.fit(x_train, y_train)\n",
        "\t\tac1.append(classifier2.score(x_test, y_test))\n",
        "\n",
        "\t\t''' split dataset into train(same as generated by our model),\n",
        "\t\ttest(25 %), unlabel(rest) '''\n",
        "\t\ttrain_size = x_train.shape[0]/dataset.shape[0]\n",
        "\t\tx_train, y_train, x_test, y_test, unlabel, label = split(\n",
        "\t\t\tdataset, train_size, 0.25)\n",
        "\n",
        "\t\t# train model without active learning\n",
        "\t\tclassifier3 = LogisticRegression()\n",
        "\t\tclassifier3.fit(x_train, y_train)\n",
        "\t\tac2.append(classifier3.score(x_test, y_test))\n",
        "\n",
        "\tprint(\"Accuracy by active model :\", mean(ac1)*100)\n",
        "\tprint(\"Accuracy by random sampling :\", mean(ac2)*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ5X0hGiFAqv",
        "outputId": "75945c93-eb20-432e-c946-62ed399971be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy by active model : 77.82433668801464\n",
            "Accuracy by random sampling : 76.0961633287976\n"
          ]
        }
      ]
    }
  ]
}